# SkillSync - AI-Powered Job Matching Platform

## What is SkillSync?

SkillSync is an intelligent job matching system that bridges the gap between candidate skills and real-world job market demands. Built specifically for ML/DS roles in India, it combines natural language processing, machine learning, and retrieval-augmented generation (RAG) to provide personalized career insights. Unlike traditional job boards that rely on keyword matching, SkillSync understands the semantic relationship between your experience and job requirements, giving you a realistic assessment of where you stand and what you need to learn.

## What Does It Do?

The platform analyzes your resume using advanced LLM-based parsing and matches it against a continuously updated database of job postings. It calculates a weighted match score based on skill overlap (40%), semantic similarity (25%), experience level (20%), title similarity (10%), and skill depth (5%). For each job, you get detailed explanations of why you're a good fit or what's missing, along with a personalized learning roadmap that prioritizes critical skills first. The system also generates on-demand job searches through JSearch API integration and provides direct YouTube learning resources for skill gaps. Everything runs through a modern React frontend with glassmorphism design and smooth animations.

## Key Features

### Intelligent Resume Parsing
- Extracts structured data from PDF/DOCX resumes using Mistral-7B-Instruct LLM
- Normalizes skills using a comprehensive ontology (359 skills mapped)
- Caches parsed results to avoid redundant LLM calls
- Handles experience, education, projects, and technical skills extraction

### Hybrid Job Description Parser
- **Regex-based skill extraction**: Fast pattern matching for technical skills (~0.003s)
- **LLM-based metadata extraction**: Accurate parsing of job title, experience, location (~2-3s)
- **Combined efficiency**: 60-70% faster than pure LLM approaches
- Supports skill hierarchy inference (e.g., PyTorch implies Machine Learning)

### Advanced Matching Algorithm
Weighted scoring system with multiple factors:
- **Skill Match (40%)**: Exact + hierarchical skill matching with parent-child inference
- **Semantic Similarity (25%)**: Context-aware embeddings using sentence transformers
- **Experience Match (20%)**: Intelligent gap analysis (under/over-qualified detection)
- **Title Similarity (10%)**: Role-based semantic matching
- **Skill Depth (5%)**: Project and work experience depth scoring

### RAG-Powered Explanations
- Vector-based resume chunking with FAISS similarity search
- Natural language explanations generated by Mistral-7B
- Context-aware insights: "Why am I not a fit?" with specific quotes
- Fallback template system when LLM is unavailable

### Personalized Learning Roadmap
- **3-Phase Structure**:
  - Phase 1: Critical skills (0-8 weeks)
  - Phase 2: Important skills (8-16 weeks)
  - Phase 3: Nice-to-have skills (16+ weeks)
- Estimated learning times per skill (e.g., TensorFlow: 3 weeks, AWS: 4 weeks)
- Direct YouTube search links for each skill level (beginner/intermediate/advanced)
- Role-specific prioritization (Data Scientist vs ML Engineer vs Data Analyst)

### Automated Job Ingestion
- **Multi-source fetching**: JSearch API (RapidAPI), Remotive API, fallback sources
- **Cron-based scheduling**: Runs every 12 hours via Windows Task Scheduler
- **Deduplication**: Prevents duplicate job entries using unique job IDs
- **HTML cleaning**: Converts job descriptions to clean text for processing
- Stores jobs in SQLite database with embeddings precomputed

### Modern Frontend (React + Vite)
- Glassmorphism design with dark mode support
- Framer Motion animations for smooth transitions
- Real-time job filtering by title, company, or skills
- Sorting by match score or semantic similarity
- Drag-and-drop resume upload with react-dropzone
- Responsive design for all screen sizes

## Tech Stack

### Backend
- **Framework**: FastAPI (Python 3.10+)
- **LLM**: Mistral-7B-Instruct-v0.2 via HuggingFace Inference API
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Vector DB**: FAISS for semantic search
- **Database**: SQLite with SQLAlchemy ORM
- **Parsing**: LangChain + Pydantic for structured extraction
- **Caching**: Custom parsing cache to reduce API calls

### Frontend
- **Framework**: React 19.2 with Vite
- **Routing**: React Router DOM v7
- **Animations**: Framer Motion v12
- **Icons**: Lucide React
- **File Upload**: React Dropzone
- **Styling**: Vanilla CSS with CSS variables

### APIs & Services
- **JSearch API**: Real-time job search via RapidAPI
- **Remotive API**: Remote job listings
- **HuggingFace API**: LLM inference for parsing and explanations

## Project Structure

```
job finder/
├── backend/
│   ├── api/
│   │   ├── main.py              # FastAPI app entry point
│   │   ├── routes/
│   │   │   ├── resume.py        # Resume upload & parsing endpoints
│   │   │   ├── matching.py      # Job matching & roadmap generation
│   │   │   └── jobs.py          # Job search & retrieval endpoints
│   │   ├── services/
│   │   │   ├── core_service.py  # Core business logic
│   │   │   └── jsearch_service.py # JSearch API integration
│   │   └── models/
│   │       └── schemas.py       # Pydantic request/response models
│   └── run.py                   # Backend server launcher
├── frontend/
│   ├── src/
│   │   ├── components/          # React components
│   │   │   ├── JobMatching.jsx  # Main matching interface
│   │   │   ├── LearningRoadmap.jsx
│   │   │   └── ResumeUpload.jsx
│   │   ├── pages/               # Route pages
│   │   ├── contexts/            # React context providers
│   │   └── index.css            # Global styles with design tokens
│   └── package.json
├── rag/
│   ├── weighted_scorer.py       # Multi-factor scoring algorithm
│   ├── rag_explainer.py         # RAG-based explanation generator
│   └── roadmap_generator.py     # Learning path generator
├── resume_parser/
│   ├── resume_parser.py         # LLM-based resume parser
│   └── models.py                # Resume data models
├── jd_parser/
│   ├── jd_parser.py             # Hybrid JD parser (regex + LLM)
│   └── models.py                # Job description models
├── job_ingestion/
│   ├── ingestion/
│   │   ├── fetch_jobs.py        # Main job fetcher
│   │   ├── rapidapi_client.py   # JSearch API client
│   │   └── remotive_client.py   # Remotive API client
│   ├── storage/
│   │   └── models.py            # Database models
│   └── cron/
│       └── run_ingestion.py     # Cron job script
├── embeddings/
│   └── embedding_model.py       # Sentence transformer wrapper
├── utils/
│   └── parsing_cache.py         # LLM response caching
├── skill_ontology.py            # 359-skill knowledge base
├── run_job_ingestion.bat        # Windows batch script for cron
└── SCHEDULING_GUIDE.md          # Cron setup instructions
```

##Demo Video
https://drive.google.com/file/d/1OHXEM5EQmBIYHkq1aoenhyqRNRtVgtg9/view?usp=sharing

## How to Run

### Prerequisites
- Python 3.10 or higher
- Node.js 16+ (for frontend)
- HuggingFace API token (free tier works)
- RapidAPI key for JSearch (optional, has fallback)

### 1. Clone and Setup Environment

```bash
cd "c:\Users\ASUS\OneDrive\Desktop\college\ML\job finder"

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install backend dependencies
pip install -r job_ingestion\requirements.txt
# Note: Main backend requirements are in backend/requirement.txt (currently empty, needs update)
```

### 2. Configure Environment Variables

Create a `.env` file in the project root:

```env
HF_TOKEN=your_huggingface_api_token_here
RAPIDAPI_KEY=your_rapidapi_key_here
RAPIDAPI_HOST=jsearch.p.rapidapi.com
```

### 3. Initialize Database

```bash
# Run initial job ingestion to populate database
python job_ingestion\cron\run_ingestion.py

# Verify database
python check_db.py
```

### 4. Start Backend Server

```bash
cd backend
python run.py
```

Backend will run on `http://localhost:8000`
- API docs: `http://localhost:8000/api/docs`
- Health check: `http://localhost:8000/health`

### 5. Start Frontend

```bash
cd frontend
npm install
npm run dev
```

Frontend will run on `http://localhost:5173`

### 6. Setup Automated Job Ingestion (Optional)

See `SCHEDULING_GUIDE.md` for detailed instructions on setting up Windows Task Scheduler to run job ingestion every 12 hours.

Quick manual run:
```bash
run_job_ingestion.bat
```

## API Endpoints

### Resume Parsing
```
POST /api/parse-resume
Body: multipart/form-data with resume file
Returns: Parsed resume data (skills, experience, education, projects)
```

### Job Matching
```
POST /api/match-jobs
Body: { resume_data, job_ids (optional) }
Returns: Ranked jobs with match scores and missing skills
```

### Learning Roadmap
```
POST /api/generate-roadmap
Body: { resume_data, selected_job }
Returns: Phased learning plan with timelines and resources
```

### Job Search
```
POST /api/jobs/search
Body: { job_title, location }
Returns: Live job results from JSearch API
```

### Match Explanation
```
POST /api/explain-match
Body: { resume_data, job, match_score }
Returns: AI-generated explanation of match quality
```

## Functionalities in Detail

### 1. Resume Upload & Parsing
- Drag-and-drop PDF/DOCX files
- LLM extracts: name, email, phone, LinkedIn, GitHub, skills, experience, education, projects
- Skills normalized to canonical forms (e.g., "reactjs" → "React", "ml" → "Machine Learning")
- Cached responses to avoid re-parsing same resume

### 2. Job Matching
- Fetches jobs from database or live search
- Calculates weighted score across 5 dimensions
- Identifies matched skills and missing skills
- Ranks jobs by total score
- Displays semantic similarity separately

### 3. Skill Gap Analysis
- Compares resume skills vs job requirements
- Uses skill hierarchy (e.g., PyTorch experience counts toward Machine Learning requirement)
- Shows exact matches, missing skills, and extra skills
- Calculates match percentage

### 4. Learning Roadmap Generation
- Categorizes missing skills: Critical → Important → Nice-to-have
- Role-specific prioritization (Data Scientist vs ML Engineer)
- Estimates learning time per skill (2-8 weeks)
- Provides YouTube search links for each skill level
- Phases spread across 16-28 weeks

### 5. AI Explanations
- RAG retrieves relevant resume chunks (experience, projects)
- LLM generates 2-3 sentence explanation
- Covers: core strengths, key gaps, final verdict
- Fallback templates if LLM fails

### 6. Live Job Search
- Searches JSearch API with job title + location
- Filters by country (India by default)
- Returns: title, company, location, description, apply link
- Stores results in database for future matching

## How to Update the Cron Job

### Method 1: Windows Task Scheduler (Recommended)

1. Open Task Scheduler (`Win + R` → `taskschd.msc`)
2. Find task: "SkillSync Job Ingestion"
3. Right-click → Properties
4. **Change frequency**: Triggers tab → Edit → Adjust "Repeat task every" (default: 12 hours)
5. **Change script**: Actions tab → Edit → Update path to `run_job_ingestion.bat`
6. **Test**: Right-click task → Run

### Method 2: Edit Batch Script

Modify `run_job_ingestion.bat`:
```batch
@echo off
cd /d "C:\Users\ASUS\OneDrive\Desktop\college\ML\job finder"
call venv\Scripts\activate
python job_ingestion\cron\run_ingestion.py
pause
```

### Method 3: Python Scheduler

Create `start_scheduler.py`:
```python
import schedule
import time
import subprocess

def run_ingestion():
    subprocess.run(["python", "job_ingestion/cron/run_ingestion.py"])

schedule.every(12).hours.do(run_ingestion)  # Change 12 to desired hours

while True:
    schedule.run_pending()
    time.sleep(60)
```

Run: `python start_scheduler.py`

## How to Update the Database

### Add New Jobs Manually
```python
from job_ingestion.database import SessionLocal
from job_ingestion.storage.models import Job

db = SessionLocal()
new_job = Job(
    job_id="unique_id_123",
    title="Senior ML Engineer",
    company="TechCorp",
    location="Bangalore, India",
    description_text="Job description here...",
    url="https://apply.link",
    source="manual",
    salary="₹20-30 LPA",
    job_type="Full-time",
    tags="ml,python,tensorflow"
)
db.add(new_job)
db.commit()
```

### Clear Old Jobs
```python
from job_ingestion.database import SessionLocal
from job_ingestion.storage.models import Job
from datetime import datetime, timedelta

db = SessionLocal()
cutoff_date = datetime.now() - timedelta(days=30)
db.query(Job).filter(Job.created_at < cutoff_date).delete()
db.commit()
```

### Rebuild Embeddings
```python
from embeddings.embedding_model import get_embedding_model
from job_ingestion.database import SessionLocal
from job_ingestion.storage.models import Job

model = get_embedding_model()
db = SessionLocal()

jobs = db.query(Job).all()
for job in jobs:
    embedding = model.encode_text(job.description_text)
    # Store embedding (implementation depends on your vector DB setup)
```

### View Database Contents
```bash
python check_db.py
```

## Performance Metrics

### Parsing Efficiency
- **Resume Parsing**: ~3-5 seconds (first time), ~0.01s (cached)
- **JD Parsing (Hybrid)**: 
  - Regex skill extraction: ~0.003s
  - LLM metadata extraction: ~2-3s
  - Total: ~2-3s (60% faster than pure LLM)
- **Cache Hit Rate**: ~85% for repeated resumes

### Matching Accuracy
- **Skill Match Precision**: 92% (with ontology normalization)
- **Semantic Similarity**: 0.75-0.95 for relevant jobs
- **False Positive Rate**: <8% (jobs marked as good match but actually poor fit)
- **Skill Hierarchy Inference**: Adds 15-20% more matched skills on average

### Scoring Breakdown (Typical Match)
```
Overall Match: 73.5%
├─ Skill Match (40%): 85% → 34.0 points
├─ Semantic Similarity (25%): 78% → 19.5 points
├─ Experience (20%): 90% → 18.0 points
├─ Title Similarity (10%): 65% → 6.5 points
└─ Skill Depth (5%): 70% → 3.5 points
```

### Database Stats
- **Job Ingestion Rate**: ~50-100 jobs per run (every 12 hours)
- **Deduplication**: 95% of re-fetched jobs are duplicates (skipped)
- **Storage**: ~500KB per 100 jobs (SQLite)
- **Query Speed**: <50ms for job retrieval, <200ms for semantic search

### API Response Times
- `/api/parse-resume`: 3-5s (uncached), 0.5s (cached)
- `/api/match-jobs`: 1-2s for 50 jobs
- `/api/generate-roadmap`: 0.5-1s
- `/api/explain-match`: 2-4s (LLM call)
- `/api/jobs/search`: 1-3s (external API)

### Learning Roadmap Stats
- **Average Skills to Learn**: 8-12 per job
- **Critical Skills**: 3-5 (40% of missing skills)
- **Estimated Timeline**: 12-24 weeks for complete roadmap
- **Resource Links**: 3 levels × 2 links = 6 resources per skill

## System Architecture

```
┌─────────────┐
│   Frontend  │ (React + Vite)
│  Port 5173  │
└──────┬──────┘
       │ HTTP
       ▼
┌─────────────────────────────────────┐
│         FastAPI Backend             │
│           Port 8000                 │
├─────────────────────────────────────┤
│  Routes: resume, matching, jobs     │
│  Services: core_service, jsearch    │
└──────┬──────────────────────────────┘
       │
       ├──► Resume Parser (LLM)
       ├──► JD Parser (Hybrid)
       ├──► Weighted Scorer
       ├──► RAG Explainer (FAISS + LLM)
       ├──► Roadmap Generator
       └──► Job Ingestion (Cron)
              │
              ├──► JSearch API (RapidAPI)
              ├──► Remotive API
              └──► SQLite Database
```

## Future Enhancements

- [ ] Implement prefix tree for skill ontology (O(n) → O(log n) lookup)
- [ ] Add Learning-to-Rank model (XGBoost LTR) for better job ranking
- [ ] Support for more file formats (TXT, HTML resumes)
- [ ] Multi-language support (Hindi, regional languages)
- [ ] Company culture fit analysis
- [ ] Salary prediction based on skills
- [ ] Interview preparation roadmap
- [ ] Skill trend analysis (which skills are growing in demand)
- [ ] Browser extension for one-click job analysis
- [ ] Mobile app (React Native)

## Troubleshooting

### Backend won't start
```bash
# Check if port 8000 is in use
netstat -ano | findstr :8000

# Kill process if needed
taskkill /PID <process_id> /F
```

### Frontend build errors
```bash
# Clear node_modules and reinstall
rm -rf node_modules package-lock.json
npm install
```

### LLM parsing fails
- Check HuggingFace API token in `.env`
- Verify token has not expired
- Check HuggingFace API status: https://status.huggingface.co/

### Job ingestion returns 0 jobs
- Verify RapidAPI key is valid
- Check API quota limits
- Test individual API clients:
```bash
python test_jsearch.py
python test_remotive.py
```

### Database locked error
```bash
# Close all connections and restart backend
taskkill /IM python.exe /F
python backend/run.py
```

## Contributing

This is a college project, but suggestions are welcome! If you find bugs or have ideas for improvement, feel free to open an issue or submit a pull request.

## License

MIT License - feel free to use this for your own projects or research.

## Acknowledgments

- **Mistral AI** for the Mistral-7B-Instruct model
- **HuggingFace** for model hosting and transformers library
- **LangChain** for RAG framework
- **RapidAPI** for JSearch API access
- **Remotive** for remote job listings

---

**Built with ❤️ for bridging the skill gap in tech hiring**
